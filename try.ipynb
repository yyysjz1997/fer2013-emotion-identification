{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/multiphase/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train!\n",
      "finish fer2013!\n",
      "数组元素总数： 66344188\n",
      "数组形状： (28708, 2311)\n",
      "数组的维度数目 2\n",
      "INFO:tensorflow:Restoring parameters from check_point_next/data_model-1\n",
      "2019-04-17 19:54:04.589375 after 2 training step(s), loss on training batch is 200.8303, learning rate is 0.010000, accuracy is 0.161133.\n",
      "2019-04-17 19:54:23.537144 after 99 training step(s), loss on training batch is 2.0252, learning rate is 0.009762, accuracy is 0.263672.\n",
      "2019-04-17 19:54:42.247466 after 196 training step(s), loss on training batch is 1.9907, learning rate is 0.009529, accuracy is 0.260742.\n",
      "2019-04-17 19:55:00.958070 after 292 training step(s), loss on training batch is 2.0132, learning rate is 0.009228, accuracy is 0.212891.\n",
      "2019-04-17 19:55:20.057120 after 389 training step(s), loss on training batch is 1.9151, learning rate is 0.009008, accuracy is 0.268555.\n",
      "2019-04-17 19:55:39.217627 after 486 training step(s), loss on training batch is 1.9047, learning rate is 0.008724, accuracy is 0.284180.\n",
      "2019-04-17 19:55:57.881558 after 582 training step(s), loss on training batch is 1.7602, learning rate is 0.008516, accuracy is 0.358398.\n",
      "2019-04-17 19:56:17.057941 after 679 training step(s), loss on training batch is 1.6829, learning rate is 0.008247, accuracy is 0.396484.\n",
      "2019-04-17 19:56:36.440444 after 776 training step(s), loss on training batch is 1.6110, learning rate is 0.008050, accuracy is 0.420898.\n",
      "2019-04-17 19:56:55.227792 after 872 training step(s), loss on training batch is 1.5730, learning rate is 0.007796, accuracy is 0.433594.\n",
      "2019-04-17 19:57:14.314080 after 969 training step(s), loss on training batch is 1.5152, learning rate is 0.007610, accuracy is 0.459961.\n",
      "2019-04-17 19:57:33.505247 after 1066 training step(s), loss on training batch is 1.4739, learning rate is 0.007370, accuracy is 0.515625.\n",
      "2019-04-17 19:57:52.154021 after 1162 training step(s), loss on training batch is 1.4954, learning rate is 0.007194, accuracy is 0.466797.\n",
      "2019-04-17 19:58:11.139645 after 1259 training step(s), loss on training batch is 1.4274, learning rate is 0.007023, accuracy is 0.505859.\n",
      "2019-04-17 19:58:30.339018 after 1356 training step(s), loss on training batch is 1.4328, learning rate is 0.006801, accuracy is 0.521484.\n",
      "2019-04-17 19:58:48.938058 after 1452 training step(s), loss on training batch is 1.4323, learning rate is 0.006639, accuracy is 0.503906.\n",
      "2019-04-17 19:59:08.139213 after 1549 training step(s), loss on training batch is 1.3231, learning rate is 0.006429, accuracy is 0.547852.\n",
      "2019-04-17 19:59:27.213051 after 1646 training step(s), loss on training batch is 1.2245, learning rate is 0.006276, accuracy is 0.625000.\n",
      "2019-04-17 19:59:45.897275 after 1742 training step(s), loss on training batch is 1.3198, learning rate is 0.006077, accuracy is 0.584961.\n",
      "2019-04-17 20:00:04.789455 after 1839 training step(s), loss on training batch is 1.1974, learning rate is 0.005933, accuracy is 0.616211.\n",
      "2019-04-17 20:00:23.946654 after 1936 training step(s), loss on training batch is 1.2267, learning rate is 0.005745, accuracy is 0.625977.\n",
      "2019-04-17 20:00:42.851228 after 2032 training step(s), loss on training batch is 1.1586, learning rate is 0.005608, accuracy is 0.648438.\n",
      "2019-04-17 20:01:02.074270 after 2129 training step(s), loss on training batch is 1.0795, learning rate is 0.005475, accuracy is 0.681641.\n",
      "2019-04-17 20:01:21.331211 after 2226 training step(s), loss on training batch is 1.1107, learning rate is 0.005302, accuracy is 0.675781.\n",
      "2019-04-17 20:01:39.905062 after 2322 training step(s), loss on training batch is 1.1053, learning rate is 0.005176, accuracy is 0.672852.\n",
      "2019-04-17 20:01:58.936188 after 2419 training step(s), loss on training batch is 0.9934, learning rate is 0.005012, accuracy is 0.731445.\n",
      "2019-04-17 20:02:17.983569 after 2516 training step(s), loss on training batch is 0.9383, learning rate is 0.004893, accuracy is 0.770508.\n",
      "2019-04-17 20:02:36.609005 after 2612 training step(s), loss on training batch is 0.9585, learning rate is 0.004738, accuracy is 0.749023.\n",
      "2019-04-17 20:02:55.807454 after 2709 training step(s), loss on training batch is 0.8596, learning rate is 0.004625, accuracy is 0.789062.\n",
      "2019-04-17 20:03:14.962126 after 2806 training step(s), loss on training batch is 0.7816, learning rate is 0.004479, accuracy is 0.816406.\n",
      "2019-04-17 20:03:33.575055 after 2902 training step(s), loss on training batch is 0.8906, learning rate is 0.004372, accuracy is 0.774414.\n",
      "2019-04-17 20:03:52.701705 after 2999 training step(s), loss on training batch is 0.7977, learning rate is 0.004268, accuracy is 0.819336.\n",
      "2019-04-17 20:04:11.972108 after 3096 training step(s), loss on training batch is 0.6859, learning rate is 0.004133, accuracy is 0.848633.\n",
      "2019-04-17 20:04:30.916808 after 3192 training step(s), loss on training batch is 0.7463, learning rate is 0.004035, accuracy is 0.825195.\n",
      "2019-04-17 20:04:49.914351 after 3289 training step(s), loss on training batch is 0.7620, learning rate is 0.003907, accuracy is 0.823242.\n",
      "2019-04-17 20:05:09.081317 after 3386 training step(s), loss on training batch is 0.7947, learning rate is 0.003814, accuracy is 0.818359.\n",
      "2019-04-17 20:05:27.906874 after 3482 training step(s), loss on training batch is 0.6512, learning rate is 0.003694, accuracy is 0.857422.\n",
      "2019-04-17 20:05:46.902338 after 3579 training step(s), loss on training batch is 0.6836, learning rate is 0.003606, accuracy is 0.863281.\n",
      "2019-04-17 20:06:06.012783 after 3676 training step(s), loss on training batch is 0.7041, learning rate is 0.003492, accuracy is 0.864258.\n",
      "2019-04-17 20:06:24.793547 after 3772 training step(s), loss on training batch is 0.5921, learning rate is 0.003408, accuracy is 0.878906.\n",
      "2019-04-17 20:06:43.691930 after 3869 training step(s), loss on training batch is 0.6189, learning rate is 0.003301, accuracy is 0.875000.\n",
      "2019-04-17 20:07:02.927494 after 3966 training step(s), loss on training batch is 0.6379, learning rate is 0.003222, accuracy is 0.870117.\n",
      "2019-04-17 20:07:21.587573 after 4062 training step(s), loss on training batch is 0.6989, learning rate is 0.003145, accuracy is 0.843750.\n",
      "2019-04-17 20:07:40.829453 after 4159 training step(s), loss on training batch is 0.6218, learning rate is 0.003046, accuracy is 0.862305.\n",
      "2019-04-17 20:08:00.025544 after 4256 training step(s), loss on training batch is 0.7490, learning rate is 0.002973, accuracy is 0.835938.\n",
      "2019-04-17 20:08:18.745029 after 4352 training step(s), loss on training batch is 0.6228, learning rate is 0.002879, accuracy is 0.876953.\n",
      "2019-04-17 20:08:38.018906 after 4449 training step(s), loss on training batch is 0.5067, learning rate is 0.002811, accuracy is 0.905273.\n",
      "2019-04-17 20:08:57.138108 after 4546 training step(s), loss on training batch is 0.5172, learning rate is 0.002722, accuracy is 0.906250.\n",
      "2019-04-17 20:09:15.903227 after 4642 training step(s), loss on training batch is 0.4873, learning rate is 0.002657, accuracy is 0.920898.\n",
      "2019-04-17 20:09:35.093150 after 4739 training step(s), loss on training batch is 0.4422, learning rate is 0.002573, accuracy is 0.931641.\n",
      "2019-04-17 20:09:54.111498 after 4836 training step(s), loss on training batch is 0.4003, learning rate is 0.002512, accuracy is 0.940430.\n",
      "2019-04-17 20:10:12.747810 after 4932 training step(s), loss on training batch is 0.4062, learning rate is 0.002452, accuracy is 0.934570.\n",
      "2019-04-17 20:10:31.627553 after 5029 training step(s), loss on training batch is 0.4143, learning rate is 0.002375, accuracy is 0.933594.\n",
      "2019-04-17 20:10:50.405294 after 5126 training step(s), loss on training batch is 0.4072, learning rate is 0.002318, accuracy is 0.940430.\n",
      "2019-04-17 20:11:08.924301 after 5222 training step(s), loss on training batch is 0.3814, learning rate is 0.002245, accuracy is 0.940430.\n",
      "2019-04-17 20:11:27.956701 after 5319 training step(s), loss on training batch is 0.4047, learning rate is 0.002191, accuracy is 0.927734.\n",
      "2019-04-17 20:11:46.918225 after 5416 training step(s), loss on training batch is 0.3698, learning rate is 0.002122, accuracy is 0.939453.\n",
      "2019-04-17 20:12:05.787905 after 5512 training step(s), loss on training batch is 0.4121, learning rate is 0.002072, accuracy is 0.923828.\n",
      "2019-04-17 20:12:24.902522 after 5609 training step(s), loss on training batch is 0.4036, learning rate is 0.002006, accuracy is 0.936523.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-17 20:12:43.878891 after 5706 training step(s), loss on training batch is 0.4040, learning rate is 0.001958, accuracy is 0.926758.\n",
      "2019-04-17 20:13:02.539719 after 5802 training step(s), loss on training batch is 0.3864, learning rate is 0.001912, accuracy is 0.947266.\n",
      "2019-04-17 20:13:21.266182 after 5899 training step(s), loss on training batch is 0.3699, learning rate is 0.001851, accuracy is 0.935547.\n",
      "2019-04-17 20:13:40.108794 after 5996 training step(s), loss on training batch is 0.3444, learning rate is 0.001807, accuracy is 0.951172.\n",
      "2019-04-17 20:13:58.697442 after 6092 training step(s), loss on training batch is 0.3420, learning rate is 0.001750, accuracy is 0.946289.\n",
      "2019-04-17 20:14:17.921813 after 6189 training step(s), loss on training batch is 0.3146, learning rate is 0.001708, accuracy is 0.961914.\n",
      "2019-04-17 20:14:36.948030 after 6286 training step(s), loss on training batch is 0.3101, learning rate is 0.001654, accuracy is 0.957031.\n",
      "2019-04-17 20:14:55.594734 after 6382 training step(s), loss on training batch is 0.2772, learning rate is 0.001615, accuracy is 0.969727.\n",
      "2019-04-17 20:15:14.894863 after 6479 training step(s), loss on training batch is 0.3035, learning rate is 0.001564, accuracy is 0.957031.\n",
      "2019-04-17 20:15:33.675799 after 6576 training step(s), loss on training batch is 0.3074, learning rate is 0.001527, accuracy is 0.952148.\n",
      "2019-04-17 20:15:52.101069 after 6672 training step(s), loss on training batch is 0.2937, learning rate is 0.001490, accuracy is 0.960938.\n",
      "2019-04-17 20:16:10.581871 after 6769 training step(s), loss on training batch is 0.2791, learning rate is 0.001443, accuracy is 0.960938.\n",
      "2019-04-17 20:16:29.651615 after 6866 training step(s), loss on training batch is 0.2571, learning rate is 0.001409, accuracy is 0.967773.\n",
      "2019-04-17 20:16:48.457386 after 6962 training step(s), loss on training batch is 0.2772, learning rate is 0.001364, accuracy is 0.965820.\n",
      "2019-04-17 20:17:07.469684 after 7059 training step(s), loss on training batch is 0.2457, learning rate is 0.001332, accuracy is 0.975586.\n",
      "2019-04-17 20:17:26.584863 after 7156 training step(s), loss on training batch is 0.2479, learning rate is 0.001290, accuracy is 0.974609.\n",
      "2019-04-17 20:17:45.187905 after 7252 training step(s), loss on training batch is 0.2459, learning rate is 0.001259, accuracy is 0.972656.\n",
      "2019-04-17 20:18:04.214251 after 7349 training step(s), loss on training batch is 0.2581, learning rate is 0.001219, accuracy is 0.963867.\n",
      "2019-04-17 20:18:23.246387 after 7446 training step(s), loss on training batch is 0.2179, learning rate is 0.001190, accuracy is 0.982422.\n",
      "2019-04-17 20:18:41.855524 after 7542 training step(s), loss on training batch is 0.2425, learning rate is 0.001152, accuracy is 0.965820.\n",
      "2019-04-17 20:19:01.112936 after 7639 training step(s), loss on training batch is 0.2197, learning rate is 0.001125, accuracy is 0.977539.\n",
      "2019-04-17 20:19:20.009308 after 7736 training step(s), loss on training batch is 0.2204, learning rate is 0.001098, accuracy is 0.978516.\n",
      "2019-04-17 20:19:38.688474 after 7832 training step(s), loss on training batch is 0.2087, learning rate is 0.001064, accuracy is 0.978516.\n",
      "2019-04-17 20:19:57.647158 after 7929 training step(s), loss on training batch is 0.2180, learning rate is 0.001038, accuracy is 0.976562.\n",
      "2019-04-17 20:20:16.759534 after 8026 training step(s), loss on training batch is 0.2180, learning rate is 0.001005, accuracy is 0.976562.\n",
      "2019-04-17 20:20:35.353120 after 8122 training step(s), loss on training batch is 0.2187, learning rate is 0.000981, accuracy is 0.977539.\n",
      "2019-04-17 20:20:54.343928 after 8219 training step(s), loss on training batch is 0.1995, learning rate is 0.000950, accuracy is 0.977539.\n",
      "2019-04-17 20:21:13.437667 after 8316 training step(s), loss on training batch is 0.2009, learning rate is 0.000928, accuracy is 0.981445.\n",
      "2019-04-17 20:21:32.314924 after 8412 training step(s), loss on training batch is 0.1977, learning rate is 0.000898, accuracy is 0.975586.\n",
      "2019-04-17 20:21:51.306484 after 8509 training step(s), loss on training batch is 0.2034, learning rate is 0.000877, accuracy is 0.972656.\n",
      "2019-04-17 20:22:10.353119 after 8606 training step(s), loss on training batch is 0.2028, learning rate is 0.000856, accuracy is 0.975586.\n",
      "2019-04-17 20:22:28.681028 after 8702 training step(s), loss on training batch is 0.2015, learning rate is 0.000829, accuracy is 0.975586.\n",
      "2019-04-17 20:22:47.650585 after 8799 training step(s), loss on training batch is 0.2048, learning rate is 0.000809, accuracy is 0.971680.\n",
      "2019-04-17 20:23:06.657517 after 8896 training step(s), loss on training batch is 0.1796, learning rate is 0.000784, accuracy is 0.983398.\n",
      "2019-04-17 20:23:25.376972 after 8992 training step(s), loss on training batch is 0.1901, learning rate is 0.000765, accuracy is 0.983398.\n",
      "2019-04-17 20:23:44.563035 after 9089 training step(s), loss on training batch is 0.1763, learning rate is 0.000741, accuracy is 0.982422.\n",
      "2019-04-17 20:24:04.013649 after 9186 training step(s), loss on training batch is 0.1694, learning rate is 0.000723, accuracy is 0.984375.\n",
      "2019-04-17 20:24:23.114201 after 9282 training step(s), loss on training batch is 0.1796, learning rate is 0.000700, accuracy is 0.979492.\n",
      "2019-04-17 20:24:42.357740 after 9379 training step(s), loss on training batch is 0.1563, learning rate is 0.000684, accuracy is 0.990234.\n",
      "2019-04-17 20:25:01.959431 after 9476 training step(s), loss on training batch is 0.1664, learning rate is 0.000662, accuracy is 0.987305.\n",
      "2019-04-17 20:25:20.846029 after 9572 training step(s), loss on training batch is 0.1710, learning rate is 0.000646, accuracy is 0.983398.\n",
      "2019-04-17 20:25:39.893188 after 9669 training step(s), loss on training batch is 0.1641, learning rate is 0.000631, accuracy is 0.982422.\n",
      "2019-04-17 20:25:59.138631 after 9766 training step(s), loss on training batch is 0.1588, learning rate is 0.000611, accuracy is 0.984375.\n",
      "2019-04-17 20:26:17.870734 after 9862 training step(s), loss on training batch is 0.1658, learning rate is 0.000596, accuracy is 0.983398.\n",
      "2019-04-17 20:26:36.889027 after 9959 training step(s), loss on training batch is 0.1545, learning rate is 0.000578, accuracy is 0.990234.\n",
      "2019-04-17 20:26:56.081840 after 10056 training step(s), loss on training batch is 0.1625, learning rate is 0.000564, accuracy is 0.983398.\n",
      "2019-04-17 20:27:14.792109 after 10152 training step(s), loss on training batch is 0.1577, learning rate is 0.000546, accuracy is 0.984375.\n",
      "2019-04-17 20:27:34.044699 after 10249 training step(s), loss on training batch is 0.1528, learning rate is 0.000533, accuracy is 0.984375.\n",
      "2019-04-17 20:27:53.202081 after 10346 training step(s), loss on training batch is 0.1527, learning rate is 0.000516, accuracy is 0.983398.\n",
      "2019-04-17 20:28:11.907674 after 10442 training step(s), loss on training batch is 0.1318, learning rate is 0.000504, accuracy is 0.991211.\n",
      "2019-04-17 20:28:31.141107 after 10539 training step(s), loss on training batch is 0.1423, learning rate is 0.000492, accuracy is 0.987305.\n",
      "2019-04-17 20:28:50.426711 after 10636 training step(s), loss on training batch is 0.1486, learning rate is 0.000476, accuracy is 0.987305.\n",
      "2019-04-17 20:29:09.270839 after 10732 training step(s), loss on training batch is 0.1384, learning rate is 0.000465, accuracy is 0.990234.\n",
      "2019-04-17 20:29:28.511321 after 10829 training step(s), loss on training batch is 0.1453, learning rate is 0.000450, accuracy is 0.987305.\n",
      "2019-04-17 20:29:47.709928 after 10926 training step(s), loss on training batch is 0.1340, learning rate is 0.000440, accuracy is 0.990234.\n",
      "2019-04-17 20:30:06.536797 after 11022 training step(s), loss on training batch is 0.1357, learning rate is 0.000426, accuracy is 0.987305.\n",
      "2019-04-17 20:30:25.706543 after 11119 training step(s), loss on training batch is 0.1330, learning rate is 0.000416, accuracy is 0.991211.\n",
      "2019-04-17 20:30:45.114035 after 11216 training step(s), loss on training batch is 0.1307, learning rate is 0.000402, accuracy is 0.991211.\n",
      "2019-04-17 20:31:03.910089 after 11312 training step(s), loss on training batch is 0.1214, learning rate is 0.000393, accuracy is 0.993164.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-17 20:31:22.985472 after 11409 training step(s), loss on training batch is 0.1365, learning rate is 0.000383, accuracy is 0.984375.\n",
      "2019-04-17 20:31:42.194708 after 11506 training step(s), loss on training batch is 0.1279, learning rate is 0.000371, accuracy is 0.991211.\n",
      "2019-04-17 20:32:00.845902 after 11602 training step(s), loss on training batch is 0.1261, learning rate is 0.000363, accuracy is 0.991211.\n",
      "2019-04-17 20:32:19.939564 after 11699 training step(s), loss on training batch is 0.1251, learning rate is 0.000351, accuracy is 0.993164.\n",
      "2019-04-17 20:32:39.382774 after 11796 training step(s), loss on training batch is 0.1319, learning rate is 0.000343, accuracy is 0.990234.\n",
      "2019-04-17 20:32:57.971052 after 11892 training step(s), loss on training batch is 0.1306, learning rate is 0.000332, accuracy is 0.989258.\n",
      "2019-04-17 20:33:17.083195 after 11989 training step(s), loss on training batch is 0.1249, learning rate is 0.000324, accuracy is 0.988281.\n",
      "2019-04-17 20:33:36.356254 after 12086 training step(s), loss on training batch is 0.1153, learning rate is 0.000314, accuracy is 0.991211.\n",
      "2019-04-17 20:33:54.982091 after 12182 training step(s), loss on training batch is 0.1173, learning rate is 0.000306, accuracy is 0.992188.\n",
      "2019-04-17 20:34:14.358300 after 12279 training step(s), loss on training batch is 0.1184, learning rate is 0.000299, accuracy is 0.988281.\n",
      "2019-04-17 20:34:33.439224 after 12376 training step(s), loss on training batch is 0.1288, learning rate is 0.000289, accuracy is 0.986328.\n",
      "2019-04-17 20:34:52.292371 after 12472 training step(s), loss on training batch is 0.1164, learning rate is 0.000283, accuracy is 0.990234.\n",
      "2019-04-17 20:35:11.316654 after 12569 training step(s), loss on training batch is 0.1199, learning rate is 0.000274, accuracy is 0.990234.\n",
      "2019-04-17 20:35:30.525772 after 12666 training step(s), loss on training batch is 0.1157, learning rate is 0.000267, accuracy is 0.991211.\n",
      "2019-04-17 20:35:49.337295 after 12762 training step(s), loss on training batch is 0.1181, learning rate is 0.000259, accuracy is 0.992188.\n",
      "2019-04-17 20:36:08.631277 after 12859 training step(s), loss on training batch is 0.1132, learning rate is 0.000253, accuracy is 0.990234.\n",
      "2019-04-17 20:36:27.965789 after 12956 training step(s), loss on training batch is 0.1207, learning rate is 0.000245, accuracy is 0.987305.\n",
      "2019-04-17 20:36:46.944557 after 13052 training step(s), loss on training batch is 0.1151, learning rate is 0.000239, accuracy is 0.987305.\n",
      "2019-04-17 20:37:06.023531 after 13149 training step(s), loss on training batch is 0.1141, learning rate is 0.000231, accuracy is 0.988281.\n",
      "2019-04-17 20:37:25.038102 after 13246 training step(s), loss on training batch is 0.1140, learning rate is 0.000226, accuracy is 0.988281.\n",
      "2019-04-17 20:37:43.675024 after 13342 training step(s), loss on training batch is 0.1094, learning rate is 0.000220, accuracy is 0.990234.\n",
      "2019-04-17 20:38:03.287718 after 13439 training step(s), loss on training batch is 0.1066, learning rate is 0.000213, accuracy is 0.992188.\n",
      "2019-04-17 20:38:22.577039 after 13536 training step(s), loss on training batch is 0.1081, learning rate is 0.000208, accuracy is 0.991211.\n",
      "2019-04-17 20:38:41.309331 after 13632 training step(s), loss on training batch is 0.1190, learning rate is 0.000202, accuracy is 0.987305.\n",
      "2019-04-17 20:39:00.364125 after 13729 training step(s), loss on training batch is 0.1063, learning rate is 0.000197, accuracy is 0.990234.\n",
      "2019-04-17 20:39:19.332884 after 13826 training step(s), loss on training batch is 0.1028, learning rate is 0.000191, accuracy is 0.994141.\n",
      "2019-04-17 20:39:37.951117 after 13922 training step(s), loss on training batch is 0.1126, learning rate is 0.000186, accuracy is 0.991211.\n",
      "2019-04-17 20:39:56.961715 after 14019 training step(s), loss on training batch is 0.1062, learning rate is 0.000180, accuracy is 0.993164.\n",
      "2019-04-17 20:40:16.210822 after 14116 training step(s), loss on training batch is 0.1011, learning rate is 0.000176, accuracy is 0.992188.\n",
      "2019-04-17 20:40:35.105081 after 14212 training step(s), loss on training batch is 0.0982, learning rate is 0.000172, accuracy is 0.992188.\n",
      "2019-04-17 20:40:54.210768 after 14309 training step(s), loss on training batch is 0.0975, learning rate is 0.000166, accuracy is 0.996094.\n",
      "2019-04-17 20:41:13.611116 after 14406 training step(s), loss on training batch is 0.1037, learning rate is 0.000162, accuracy is 0.994141.\n",
      "2019-04-17 20:41:32.405029 after 14502 training step(s), loss on training batch is 0.1012, learning rate is 0.000157, accuracy is 0.990234.\n",
      "2019-04-17 20:41:51.484655 after 14599 training step(s), loss on training batch is 0.1029, learning rate is 0.000153, accuracy is 0.991211.\n",
      "2019-04-17 20:42:10.616340 after 14696 training step(s), loss on training batch is 0.1008, learning rate is 0.000149, accuracy is 0.993164.\n",
      "2019-04-17 20:42:29.822098 after 14792 training step(s), loss on training batch is 0.1034, learning rate is 0.000145, accuracy is 0.994141.\n",
      "2019-04-17 20:42:48.828082 after 14889 training step(s), loss on training batch is 0.0980, learning rate is 0.000141, accuracy is 0.995117.\n",
      "2019-04-17 20:43:07.900279 after 14986 training step(s), loss on training batch is 0.0986, learning rate is 0.000137, accuracy is 0.990234.\n",
      "2019-04-17 20:43:26.735985 after 15082 training step(s), loss on training batch is 0.1026, learning rate is 0.000134, accuracy is 0.992188.\n",
      "2019-04-17 20:43:45.973351 after 15179 training step(s), loss on training batch is 0.1024, learning rate is 0.000130, accuracy is 0.989258.\n",
      "2019-04-17 20:44:05.007343 after 15276 training step(s), loss on training batch is 0.0938, learning rate is 0.000127, accuracy is 0.992188.\n",
      "2019-04-17 20:44:23.825140 after 15372 training step(s), loss on training batch is 0.0943, learning rate is 0.000123, accuracy is 0.992188.\n",
      "2019-04-17 20:44:42.914921 after 15469 training step(s), loss on training batch is 0.0978, learning rate is 0.000120, accuracy is 0.993164.\n",
      "2019-04-17 20:45:02.064420 after 15566 training step(s), loss on training batch is 0.0986, learning rate is 0.000116, accuracy is 0.993164.\n",
      "2019-04-17 20:45:21.026278 after 15662 training step(s), loss on training batch is 0.0970, learning rate is 0.000113, accuracy is 0.993164.\n",
      "2019-04-17 20:45:40.045104 after 15759 training step(s), loss on training batch is 0.0926, learning rate is 0.000110, accuracy is 0.994141.\n",
      "2019-04-17 20:45:59.171551 after 15856 training step(s), loss on training batch is 0.0905, learning rate is 0.000107, accuracy is 0.996094.\n",
      "2019-04-17 20:46:18.453055 after 15952 training step(s), loss on training batch is 0.0943, learning rate is 0.000104, accuracy is 0.994141.\n",
      "2019-04-17 20:46:37.890588 after 16049 training step(s), loss on training batch is 0.0908, learning rate is 0.000101, accuracy is 0.994141.\n",
      "2019-04-17 20:46:57.102392 after 16146 training step(s), loss on training batch is 0.0989, learning rate is 0.000099, accuracy is 0.992188.\n",
      "2019-04-17 20:47:15.893794 after 16242 training step(s), loss on training batch is 0.0942, learning rate is 0.000096, accuracy is 0.992188.\n",
      "2019-04-17 20:47:34.972804 after 16339 training step(s), loss on training batch is 0.0894, learning rate is 0.000093, accuracy is 0.995117.\n",
      "2019-04-17 20:47:54.138016 after 16436 training step(s), loss on training batch is 0.0914, learning rate is 0.000090, accuracy is 0.996094.\n",
      "2019-04-17 20:48:13.098309 after 16532 training step(s), loss on training batch is 0.0944, learning rate is 0.000088, accuracy is 0.992188.\n",
      "2019-04-17 20:48:32.290170 after 16629 training step(s), loss on training batch is 0.0830, learning rate is 0.000085, accuracy is 0.998047.\n",
      "2019-04-17 20:48:51.340130 after 16726 training step(s), loss on training batch is 0.0904, learning rate is 0.000083, accuracy is 0.995117.\n",
      "2019-04-17 20:49:10.064043 after 16822 training step(s), loss on training batch is 0.0880, learning rate is 0.000081, accuracy is 0.995117.\n",
      "2019-04-17 20:49:29.079217 after 16919 training step(s), loss on training batch is 0.0970, learning rate is 0.000079, accuracy is 0.991211.\n",
      "2019-04-17 20:49:48.516571 after 17016 training step(s), loss on training batch is 0.0920, learning rate is 0.000077, accuracy is 0.993164.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-17 20:50:07.367781 after 17112 training step(s), loss on training batch is 0.0941, learning rate is 0.000074, accuracy is 0.990234.\n",
      "2019-04-17 20:50:26.665430 after 17209 training step(s), loss on training batch is 0.0931, learning rate is 0.000073, accuracy is 0.991211.\n",
      "2019-04-17 20:50:45.817459 after 17306 training step(s), loss on training batch is 0.0957, learning rate is 0.000070, accuracy is 0.993164.\n",
      "2019-04-17 20:51:04.661158 after 17402 training step(s), loss on training batch is 0.0885, learning rate is 0.000069, accuracy is 0.991211.\n",
      "2019-04-17 20:51:23.904176 after 17499 training step(s), loss on training batch is 0.0848, learning rate is 0.000067, accuracy is 0.997070.\n",
      "2019-04-17 20:51:43.097325 after 17596 training step(s), loss on training batch is 0.0922, learning rate is 0.000065, accuracy is 0.991211.\n",
      "2019-04-17 20:52:02.020577 after 17692 training step(s), loss on training batch is 0.0876, learning rate is 0.000063, accuracy is 0.993164.\n",
      "2019-04-17 20:52:21.095749 after 17789 training step(s), loss on training batch is 0.0922, learning rate is 0.000061, accuracy is 0.993164.\n",
      "2019-04-17 20:52:40.150718 after 17886 training step(s), loss on training batch is 0.0935, learning rate is 0.000060, accuracy is 0.990234.\n",
      "2019-04-17 20:52:58.760746 after 17982 training step(s), loss on training batch is 0.0877, learning rate is 0.000058, accuracy is 0.993164.\n",
      "2019-04-17 20:53:17.993290 after 18079 training step(s), loss on training batch is 0.0810, learning rate is 0.000057, accuracy is 0.997070.\n",
      "2019-04-17 20:53:37.142186 after 18176 training step(s), loss on training batch is 0.0927, learning rate is 0.000055, accuracy is 0.991211.\n",
      "2019-04-17 20:53:55.811762 after 18272 training step(s), loss on training batch is 0.0853, learning rate is 0.000054, accuracy is 0.994141.\n",
      "2019-04-17 20:54:15.013485 after 18369 training step(s), loss on training batch is 0.0842, learning rate is 0.000052, accuracy is 0.994141.\n",
      "2019-04-17 20:54:34.213045 after 18466 training step(s), loss on training batch is 0.0861, learning rate is 0.000051, accuracy is 0.995117.\n",
      "2019-04-17 20:54:52.831852 after 18562 training step(s), loss on training batch is 0.0898, learning rate is 0.000049, accuracy is 0.995117.\n",
      "2019-04-17 20:55:11.965143 after 18659 training step(s), loss on training batch is 0.0847, learning rate is 0.000048, accuracy is 0.994141.\n",
      "2019-04-17 20:55:31.342244 after 18756 training step(s), loss on training batch is 0.0843, learning rate is 0.000046, accuracy is 0.995117.\n",
      "2019-04-17 20:55:49.976627 after 18852 training step(s), loss on training batch is 0.0855, learning rate is 0.000045, accuracy is 0.995117.\n",
      "2019-04-17 20:56:09.120169 after 18949 training step(s), loss on training batch is 0.0864, learning rate is 0.000044, accuracy is 0.994141.\n",
      "2019-04-17 20:56:28.162750 after 19046 training step(s), loss on training batch is 0.0929, learning rate is 0.000043, accuracy is 0.994141.\n",
      "2019-04-17 20:56:46.925298 after 19142 training step(s), loss on training batch is 0.0835, learning rate is 0.000042, accuracy is 0.996094.\n",
      "2019-04-17 20:57:06.023727 after 19239 training step(s), loss on training batch is 0.0821, learning rate is 0.000040, accuracy is 0.995117.\n",
      "2019-04-17 20:57:25.181998 after 19336 training step(s), loss on training batch is 0.0901, learning rate is 0.000039, accuracy is 0.994141.\n",
      "2019-04-17 20:57:43.907380 after 19432 training step(s), loss on training batch is 0.0832, learning rate is 0.000038, accuracy is 0.994141.\n",
      "2019-04-17 20:58:03.069244 after 19529 training step(s), loss on training batch is 0.0829, learning rate is 0.000037, accuracy is 0.994141.\n",
      "2019-04-17 20:58:22.125945 after 19626 training step(s), loss on training batch is 0.0923, learning rate is 0.000036, accuracy is 0.990234.\n",
      "2019-04-17 20:58:40.844156 after 19722 training step(s), loss on training batch is 0.0794, learning rate is 0.000035, accuracy is 0.997070.\n",
      "2019-04-17 20:59:00.022161 after 19819 training step(s), loss on training batch is 0.0807, learning rate is 0.000034, accuracy is 0.995117.\n",
      "2019-04-17 20:59:19.385723 after 19916 training step(s), loss on training batch is 0.0919, learning rate is 0.000033, accuracy is 0.991211.\n",
      "2019-04-17 20:59:38.105425 after 20012 training step(s), loss on training batch is 0.0894, learning rate is 0.000033, accuracy is 0.994141.\n",
      "2019-04-17 20:59:57.157418 after 20109 training step(s), loss on training batch is 0.0836, learning rate is 0.000032, accuracy is 0.993164.\n",
      "2019-04-17 21:00:16.198129 after 20206 training step(s), loss on training batch is 0.0829, learning rate is 0.000031, accuracy is 0.996094.\n",
      "2019-04-17 21:00:34.933927 after 20302 training step(s), loss on training batch is 0.0843, learning rate is 0.000030, accuracy is 0.992188.\n",
      "2019-04-17 21:00:54.098519 after 20399 training step(s), loss on training batch is 0.0817, learning rate is 0.000029, accuracy is 0.997070.\n",
      "2019-04-17 21:01:13.179958 after 20496 training step(s), loss on training batch is 0.0887, learning rate is 0.000028, accuracy is 0.994141.\n",
      "2019-04-17 21:01:31.950168 after 20592 training step(s), loss on training batch is 0.0826, learning rate is 0.000028, accuracy is 0.992188.\n",
      "2019-04-17 21:01:50.970872 after 20689 training step(s), loss on training batch is 0.0823, learning rate is 0.000027, accuracy is 0.997070.\n",
      "2019-04-17 21:02:10.273482 after 20786 training step(s), loss on training batch is 0.0853, learning rate is 0.000026, accuracy is 0.993164.\n",
      "2019-04-17 21:02:28.917161 after 20882 training step(s), loss on training batch is 0.0830, learning rate is 0.000025, accuracy is 0.994141.\n",
      "2019-04-17 21:02:47.989262 after 20979 training step(s), loss on training batch is 0.0819, learning rate is 0.000025, accuracy is 0.995117.\n",
      "2019-04-17 21:03:07.174849 after 21076 training step(s), loss on training batch is 0.0794, learning rate is 0.000024, accuracy is 0.998047.\n",
      "2019-04-17 21:03:26.167731 after 21172 training step(s), loss on training batch is 0.0891, learning rate is 0.000023, accuracy is 0.992188.\n",
      "2019-04-17 21:03:45.343002 after 21269 training step(s), loss on training batch is 0.0825, learning rate is 0.000023, accuracy is 0.994141.\n",
      "2019-04-17 21:04:04.367712 after 21366 training step(s), loss on training batch is 0.0851, learning rate is 0.000022, accuracy is 0.994141.\n",
      "2019-04-17 21:04:23.063660 after 21462 training step(s), loss on training batch is 0.0867, learning rate is 0.000021, accuracy is 0.992188.\n",
      "2019-04-17 21:04:42.489795 after 21559 training step(s), loss on training batch is 0.0841, learning rate is 0.000021, accuracy is 0.993164.\n",
      "2019-04-17 21:05:01.701404 after 21656 training step(s), loss on training batch is 0.0783, learning rate is 0.000020, accuracy is 0.997070.\n",
      "2019-04-17 21:05:20.537701 after 21752 training step(s), loss on training batch is 0.0855, learning rate is 0.000020, accuracy is 0.995117.\n",
      "2019-04-17 21:05:39.607810 after 21849 training step(s), loss on training batch is 0.0809, learning rate is 0.000019, accuracy is 0.994141.\n",
      "2019-04-17 21:05:58.721692 after 21946 training step(s), loss on training batch is 0.0876, learning rate is 0.000019, accuracy is 0.993164.\n",
      "2019-04-17 21:06:17.505600 after 22042 training step(s), loss on training batch is 0.0871, learning rate is 0.000018, accuracy is 0.992188.\n",
      "2019-04-17 21:06:36.518362 after 22139 training step(s), loss on training batch is 0.0776, learning rate is 0.000018, accuracy is 0.997070.\n",
      "2019-04-17 21:06:55.789977 after 22236 training step(s), loss on training batch is 0.0804, learning rate is 0.000017, accuracy is 0.995117.\n",
      "2019-04-17 21:07:14.637021 after 22332 training step(s), loss on training batch is 0.0848, learning rate is 0.000017, accuracy is 0.993164.\n",
      "2019-04-17 21:07:33.665396 after 22429 training step(s), loss on training batch is 0.0780, learning rate is 0.000016, accuracy is 0.996094.\n",
      "2019-04-17 21:07:52.945490 after 22526 training step(s), loss on training batch is 0.0828, learning rate is 0.000016, accuracy is 0.994141.\n",
      "2019-04-17 21:08:11.773679 after 22622 training step(s), loss on training batch is 0.0775, learning rate is 0.000015, accuracy is 0.996094.\n",
      "2019-04-17 21:08:30.807052 after 22719 training step(s), loss on training batch is 0.0864, learning rate is 0.000015, accuracy is 0.994141.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-17 21:08:50.216786 after 22816 training step(s), loss on training batch is 0.0795, learning rate is 0.000015, accuracy is 0.995117.\n",
      "2019-04-17 21:09:09.201589 after 22912 training step(s), loss on training batch is 0.0853, learning rate is 0.000014, accuracy is 0.993164.\n",
      "2019-04-17 21:09:28.370888 after 23009 training step(s), loss on training batch is 0.0835, learning rate is 0.000014, accuracy is 0.993164.\n",
      "2019-04-17 21:09:47.412055 after 23106 training step(s), loss on training batch is 0.0844, learning rate is 0.000013, accuracy is 0.990234.\n",
      "2019-04-17 21:10:06.105589 after 23202 training step(s), loss on training batch is 0.0823, learning rate is 0.000013, accuracy is 0.995117.\n",
      "2019-04-17 21:10:25.037191 after 23299 training step(s), loss on training batch is 0.0770, learning rate is 0.000013, accuracy is 0.997070.\n",
      "2019-04-17 21:10:43.980143 after 23396 training step(s), loss on training batch is 0.0776, learning rate is 0.000012, accuracy is 0.996094.\n",
      "2019-04-17 21:11:02.654729 after 23492 training step(s), loss on training batch is 0.0815, learning rate is 0.000012, accuracy is 0.994141.\n",
      "2019-04-17 21:11:21.751435 after 23589 training step(s), loss on training batch is 0.0754, learning rate is 0.000012, accuracy is 0.997070.\n",
      "2019-04-17 21:11:40.951393 after 23686 training step(s), loss on training batch is 0.0785, learning rate is 0.000011, accuracy is 0.996094.\n",
      "2019-04-17 21:11:59.750625 after 23782 training step(s), loss on training batch is 0.0799, learning rate is 0.000011, accuracy is 0.995117.\n",
      "2019-04-17 21:12:18.768629 after 23879 training step(s), loss on training batch is 0.0725, learning rate is 0.000011, accuracy is 0.998047.\n",
      "2019-04-17 21:12:37.798855 after 23976 training step(s), loss on training batch is 0.0805, learning rate is 0.000010, accuracy is 0.995117.\n",
      "2019-04-17 21:12:56.506045 after 24072 training step(s), loss on training batch is 0.0801, learning rate is 0.000010, accuracy is 0.994141.\n",
      "2019-04-17 21:13:15.694609 after 24169 training step(s), loss on training batch is 0.0716, learning rate is 0.000010, accuracy is 0.998047.\n",
      "2019-04-17 21:13:34.727286 after 24266 training step(s), loss on training batch is 0.0853, learning rate is 0.000010, accuracy is 0.992188.\n",
      "2019-04-17 21:13:53.223695 after 24362 training step(s), loss on training batch is 0.0762, learning rate is 0.000009, accuracy is 0.997070.\n",
      "2019-04-17 21:14:12.219466 after 24459 training step(s), loss on training batch is 0.0780, learning rate is 0.000009, accuracy is 0.996094.\n",
      "2019-04-17 21:14:31.259838 after 24556 training step(s), loss on training batch is 0.0826, learning rate is 0.000009, accuracy is 0.994141.\n",
      "2019-04-17 21:14:50.237526 after 24652 training step(s), loss on training batch is 0.0788, learning rate is 0.000009, accuracy is 0.995117.\n",
      "2019-04-17 21:15:09.410108 after 24749 training step(s), loss on training batch is 0.0741, learning rate is 0.000008, accuracy is 0.997070.\n",
      "2019-04-17 21:15:28.430641 after 24846 training step(s), loss on training batch is 0.0806, learning rate is 0.000008, accuracy is 0.996094.\n",
      "2019-04-17 21:15:47.061477 after 24942 training step(s), loss on training batch is 0.0759, learning rate is 0.000008, accuracy is 0.996094.\n",
      "2019-04-17 21:16:06.186835 after 25039 training step(s), loss on training batch is 0.0791, learning rate is 0.000008, accuracy is 0.995117.\n",
      "2019-04-17 21:16:25.330820 after 25136 training step(s), loss on training batch is 0.0831, learning rate is 0.000007, accuracy is 0.993164.\n",
      "2019-04-17 21:16:43.952902 after 25232 training step(s), loss on training batch is 0.0776, learning rate is 0.000007, accuracy is 0.995117.\n",
      "2019-04-17 21:17:03.103799 after 25329 training step(s), loss on training batch is 0.0755, learning rate is 0.000007, accuracy is 0.997070.\n",
      "2019-04-17 21:17:22.260923 after 25426 training step(s), loss on training batch is 0.0824, learning rate is 0.000007, accuracy is 0.991211.\n",
      "2019-04-17 21:17:41.010240 after 25522 training step(s), loss on training batch is 0.0775, learning rate is 0.000007, accuracy is 0.994141.\n",
      "2019-04-17 21:18:00.053953 after 25619 training step(s), loss on training batch is 0.0798, learning rate is 0.000007, accuracy is 0.995117.\n",
      "2019-04-17 21:18:19.245172 after 25716 training step(s), loss on training batch is 0.0853, learning rate is 0.000006, accuracy is 0.991211.\n",
      "2019-04-17 21:18:38.100718 after 25812 training step(s), loss on training batch is 0.0817, learning rate is 0.000006, accuracy is 0.994141.\n",
      "2019-04-17 21:18:57.427784 after 25909 training step(s), loss on training batch is 0.0760, learning rate is 0.000006, accuracy is 0.996094.\n",
      "2019-04-17 21:19:16.365896 after 26006 training step(s), loss on training batch is 0.0784, learning rate is 0.000006, accuracy is 0.995117.\n",
      "2019-04-17 21:19:35.006647 after 26102 training step(s), loss on training batch is 0.0822, learning rate is 0.000006, accuracy is 0.995117.\n",
      "2019-04-17 21:19:54.099228 after 26199 training step(s), loss on training batch is 0.0772, learning rate is 0.000006, accuracy is 0.996094.\n",
      "2019-04-17 21:20:13.113029 after 26296 training step(s), loss on training batch is 0.0829, learning rate is 0.000005, accuracy is 0.993164.\n",
      "2019-04-17 21:20:31.948975 after 26392 training step(s), loss on training batch is 0.0780, learning rate is 0.000005, accuracy is 0.994141.\n",
      "2019-04-17 21:20:50.855709 after 26489 training step(s), loss on training batch is 0.0751, learning rate is 0.000005, accuracy is 0.996094.\n",
      "2019-04-17 21:21:10.358743 after 26586 training step(s), loss on training batch is 0.0835, learning rate is 0.000005, accuracy is 0.993164.\n",
      "2019-04-17 21:21:29.029582 after 26682 training step(s), loss on training batch is 0.0768, learning rate is 0.000005, accuracy is 0.996094.\n",
      "2019-04-17 21:21:48.138580 after 26779 training step(s), loss on training batch is 0.0742, learning rate is 0.000005, accuracy is 0.998047.\n",
      "2019-04-17 21:22:07.342620 after 26876 training step(s), loss on training batch is 0.0836, learning rate is 0.000005, accuracy is 0.992188.\n",
      "2019-04-17 21:22:26.088268 after 26972 training step(s), loss on training batch is 0.0782, learning rate is 0.000004, accuracy is 0.994141.\n",
      "2019-04-17 21:22:45.375852 after 27069 training step(s), loss on training batch is 0.0827, learning rate is 0.000004, accuracy is 0.993164.\n",
      "2019-04-17 21:23:04.810745 after 27166 training step(s), loss on training batch is 0.0783, learning rate is 0.000004, accuracy is 0.997070.\n",
      "2019-04-17 21:23:23.581773 after 27262 training step(s), loss on training batch is 0.0877, learning rate is 0.000004, accuracy is 0.993164.\n",
      "2019-04-17 21:23:42.650811 after 27359 training step(s), loss on training batch is 0.0776, learning rate is 0.000004, accuracy is 0.994141.\n",
      "2019-04-17 21:24:01.948331 after 27456 training step(s), loss on training batch is 0.0863, learning rate is 0.000004, accuracy is 0.989258.\n",
      "2019-04-17 21:24:21.142664 after 27552 training step(s), loss on training batch is 0.0796, learning rate is 0.000004, accuracy is 0.994141.\n",
      "2019-04-17 21:24:40.264953 after 27649 training step(s), loss on training batch is 0.0750, learning rate is 0.000004, accuracy is 0.996094.\n",
      "2019-04-17 21:24:59.464849 after 27746 training step(s), loss on training batch is 0.0801, learning rate is 0.000004, accuracy is 0.996094.\n",
      "2019-04-17 21:25:18.345108 after 27842 training step(s), loss on training batch is 0.0799, learning rate is 0.000003, accuracy is 0.991211.\n",
      "2019-04-17 21:25:37.508119 after 27939 training step(s), loss on training batch is 0.0766, learning rate is 0.000003, accuracy is 0.996094.\n",
      "2019-04-17 21:25:56.492242 after 28036 training step(s), loss on training batch is 0.0827, learning rate is 0.000003, accuracy is 0.993164.\n",
      "2019-04-17 21:26:15.072712 after 28132 training step(s), loss on training batch is 0.0778, learning rate is 0.000003, accuracy is 0.995117.\n",
      "2019-04-17 21:26:33.683380 after 28229 training step(s), loss on training batch is 0.0750, learning rate is 0.000003, accuracy is 0.997070.\n",
      "2019-04-17 21:26:52.858255 after 28326 training step(s), loss on training batch is 0.0780, learning rate is 0.000003, accuracy is 0.995117.\n",
      "2019-04-17 21:27:11.535982 after 28422 training step(s), loss on training batch is 0.0799, learning rate is 0.000003, accuracy is 0.995117.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-17 21:27:30.559129 after 28519 training step(s), loss on training batch is 0.0789, learning rate is 0.000003, accuracy is 0.996094.\n",
      "2019-04-17 21:27:49.797128 after 28616 training step(s), loss on training batch is 0.0797, learning rate is 0.000003, accuracy is 0.994141.\n",
      "2019-04-17 21:28:08.507099 after 28712 training step(s), loss on training batch is 0.0821, learning rate is 0.000003, accuracy is 0.992188.\n",
      "2019-04-17 21:28:27.514829 after 28809 training step(s), loss on training batch is 0.0741, learning rate is 0.000003, accuracy is 0.997070.\n",
      "2019-04-17 21:28:46.710420 after 28906 training step(s), loss on training batch is 0.0798, learning rate is 0.000003, accuracy is 0.994141.\n",
      "2019-04-17 21:29:05.660168 after 29002 training step(s), loss on training batch is 0.0780, learning rate is 0.000002, accuracy is 0.995117.\n",
      "2019-04-17 21:29:25.036723 after 29099 training step(s), loss on training batch is 0.0796, learning rate is 0.000002, accuracy is 0.994141.\n",
      "2019-04-17 21:29:44.145255 after 29196 training step(s), loss on training batch is 0.0794, learning rate is 0.000002, accuracy is 0.995117.\n",
      "2019-04-17 21:30:03.080126 after 29292 training step(s), loss on training batch is 0.0788, learning rate is 0.000002, accuracy is 0.995117.\n",
      "2019-04-17 21:30:22.242300 after 29389 training step(s), loss on training batch is 0.0727, learning rate is 0.000002, accuracy is 0.998047.\n",
      "2019-04-17 21:30:41.237728 after 29486 training step(s), loss on training batch is 0.0838, learning rate is 0.000002, accuracy is 0.994141.\n",
      "2019-04-17 21:31:00.033053 after 29582 training step(s), loss on training batch is 0.0820, learning rate is 0.000002, accuracy is 0.993164.\n",
      "2019-04-17 21:31:18.927299 after 29679 training step(s), loss on training batch is 0.0793, learning rate is 0.000002, accuracy is 0.994141.\n",
      "2019-04-17 21:31:38.002192 after 29776 training step(s), loss on training batch is 0.0807, learning rate is 0.000002, accuracy is 0.993164.\n",
      "2019-04-17 21:31:56.834205 after 29872 training step(s), loss on training batch is 0.0806, learning rate is 0.000002, accuracy is 0.993164.\n",
      "2019-04-17 21:32:16.051054 after 29969 training step(s), loss on training batch is 0.0789, learning rate is 0.000002, accuracy is 0.994141.\n",
      "2019-04-17 21:32:35.105322 after 30066 training step(s), loss on training batch is 0.0840, learning rate is 0.000002, accuracy is 0.994141.\n",
      "2019-04-17 21:32:53.761640 after 30162 training step(s), loss on training batch is 0.0763, learning rate is 0.000002, accuracy is 0.995117.\n",
      "2019-04-17 21:33:12.626436 after 30259 training step(s), loss on training batch is 0.0796, learning rate is 0.000002, accuracy is 0.994141.\n",
      "2019-04-17 21:33:31.619280 after 30356 training step(s), loss on training batch is 0.0792, learning rate is 0.000002, accuracy is 0.995117.\n",
      "2019-04-17 21:33:50.274847 after 30452 training step(s), loss on training batch is 0.0819, learning rate is 0.000002, accuracy is 0.994141.\n",
      "2019-04-17 21:34:09.589710 after 30549 training step(s), loss on training batch is 0.0799, learning rate is 0.000002, accuracy is 0.995117.\n",
      "2019-04-17 21:34:29.002004 after 30646 training step(s), loss on training batch is 0.0828, learning rate is 0.000002, accuracy is 0.994141.\n",
      "2019-04-17 21:34:47.622342 after 30742 training step(s), loss on training batch is 0.0772, learning rate is 0.000002, accuracy is 0.994141.\n",
      "2019-04-17 21:35:06.872967 after 30839 training step(s), loss on training batch is 0.0831, learning rate is 0.000001, accuracy is 0.993164.\n",
      "2019-04-17 21:35:25.950125 after 30936 training step(s), loss on training batch is 0.0740, learning rate is 0.000001, accuracy is 0.996094.\n",
      "2019-04-17 21:35:44.575468 after 31032 training step(s), loss on training batch is 0.0778, learning rate is 0.000001, accuracy is 0.995117.\n",
      "2019-04-17 21:36:04.064006 after 31129 training step(s), loss on training batch is 0.0741, learning rate is 0.000001, accuracy is 0.997070.\n",
      "2019-04-17 21:36:23.317400 after 31226 training step(s), loss on training batch is 0.0796, learning rate is 0.000001, accuracy is 0.995117.\n",
      "2019-04-17 21:36:41.946332 after 31322 training step(s), loss on training batch is 0.0792, learning rate is 0.000001, accuracy is 0.994141.\n",
      "2019-04-17 21:37:00.938282 after 31419 training step(s), loss on training batch is 0.0824, learning rate is 0.000001, accuracy is 0.993164.\n",
      "2019-04-17 21:37:20.048572 after 31516 training step(s), loss on training batch is 0.0770, learning rate is 0.000001, accuracy is 0.996094.\n",
      "2019-04-17 21:37:38.870061 after 31612 training step(s), loss on training batch is 0.0815, learning rate is 0.000001, accuracy is 0.995117.\n",
      "2019-04-17 21:37:57.950528 after 31709 training step(s), loss on training batch is 0.0731, learning rate is 0.000001, accuracy is 0.998047.\n",
      "2019-04-17 21:38:17.228267 after 31806 training step(s), loss on training batch is 0.0843, learning rate is 0.000001, accuracy is 0.993164.\n",
      "2019-04-17 21:38:35.848067 after 31902 training step(s), loss on training batch is 0.0780, learning rate is 0.000001, accuracy is 0.995117.\n",
      "2019-04-17 21:38:54.811434 after 31999 training step(s), loss on training batch is 0.0789, learning rate is 0.000001, accuracy is 0.995117.\n",
      "2019-04-17 21:39:13.891092 after 32096 training step(s), loss on training batch is 0.0756, learning rate is 0.000001, accuracy is 0.996094.\n",
      "2019-04-17 21:39:32.552933 after 32192 training step(s), loss on training batch is 0.0822, learning rate is 0.000001, accuracy is 0.994141.\n",
      "2019-04-17 21:39:51.523160 after 32289 training step(s), loss on training batch is 0.0734, learning rate is 0.000001, accuracy is 0.998047.\n",
      "2019-04-17 21:40:10.736762 after 32386 training step(s), loss on training batch is 0.0807, learning rate is 0.000001, accuracy is 0.994141.\n",
      "2019-04-17 21:40:29.508309 after 32482 training step(s), loss on training batch is 0.0815, learning rate is 0.000001, accuracy is 0.992188.\n",
      "2019-04-17 21:40:48.697832 after 32579 training step(s), loss on training batch is 0.0838, learning rate is 0.000001, accuracy is 0.994141.\n",
      "2019-04-17 21:41:07.731395 after 32676 training step(s), loss on training batch is 0.0784, learning rate is 0.000001, accuracy is 0.994141.\n",
      "2019-04-17 21:41:26.618542 after 32772 training step(s), loss on training batch is 0.0770, learning rate is 0.000001, accuracy is 0.994141.\n",
      "2019-04-17 21:41:45.622780 after 32869 training step(s), loss on training batch is 0.0763, learning rate is 0.000001, accuracy is 0.995117.\n",
      "2019-04-17 21:42:04.868320 after 32966 training step(s), loss on training batch is 0.0811, learning rate is 0.000001, accuracy is 0.995117.\n",
      "2019-04-17 21:42:23.806632 after 33062 training step(s), loss on training batch is 0.0782, learning rate is 0.000001, accuracy is 0.994141.\n",
      "2019-04-17 21:42:42.965828 after 33159 training step(s), loss on training batch is 0.0745, learning rate is 0.000001, accuracy is 0.998047.\n",
      "2019-04-17 21:43:02.013477 after 33256 training step(s), loss on training batch is 0.0757, learning rate is 0.000001, accuracy is 0.996094.\n",
      "2019-04-17 21:43:20.963158 after 33352 training step(s), loss on training batch is 0.0751, learning rate is 0.000001, accuracy is 0.996094.\n",
      "2019-04-17 21:43:39.976202 after 33449 training step(s), loss on training batch is 0.0781, learning rate is 0.000001, accuracy is 0.993164.\n",
      "2019-04-17 21:43:59.073411 after 33546 training step(s), loss on training batch is 0.0828, learning rate is 0.000001, accuracy is 0.994141.\n",
      "2019-04-17 21:44:18.001854 after 33642 training step(s), loss on training batch is 0.0761, learning rate is 0.000001, accuracy is 0.997070.\n",
      "2019-04-17 21:44:37.340341 after 33739 training step(s), loss on training batch is 0.0779, learning rate is 0.000001, accuracy is 0.993164.\n",
      "2019-04-17 21:44:56.513677 after 33836 training step(s), loss on training batch is 0.0786, learning rate is 0.000001, accuracy is 0.997070.\n",
      "2019-04-17 21:45:15.171509 after 33932 training step(s), loss on training batch is 0.0764, learning rate is 0.000001, accuracy is 0.995117.\n",
      "2019-04-17 21:45:34.401610 after 34029 training step(s), loss on training batch is 0.0795, learning rate is 0.000001, accuracy is 0.991211.\n",
      "2019-04-17 21:45:53.428095 after 34126 training step(s), loss on training batch is 0.0830, learning rate is 0.000001, accuracy is 0.992188.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-17 21:46:12.174478 after 34222 training step(s), loss on training batch is 0.0794, learning rate is 0.000001, accuracy is 0.994141.\n",
      "2019-04-17 21:46:31.385807 after 34319 training step(s), loss on training batch is 0.0785, learning rate is 0.000001, accuracy is 0.995117.\n",
      "2019-04-17 21:46:50.739150 after 34416 training step(s), loss on training batch is 0.0829, learning rate is 0.000001, accuracy is 0.995117.\n",
      "2019-04-17 21:47:09.222827 after 34512 training step(s), loss on training batch is 0.0844, learning rate is 0.000001, accuracy is 0.992188.\n",
      "2019-04-17 21:47:28.149999 after 34609 training step(s), loss on training batch is 0.0775, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 21:47:47.194296 after 34706 training step(s), loss on training batch is 0.0839, learning rate is 0.000000, accuracy is 0.991211.\n",
      "2019-04-17 21:48:05.893574 after 34802 training step(s), loss on training batch is 0.0860, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 21:48:25.096868 after 34899 training step(s), loss on training batch is 0.0804, learning rate is 0.000000, accuracy is 0.992188.\n",
      "2019-04-17 21:48:44.236176 after 34996 training step(s), loss on training batch is 0.0847, learning rate is 0.000000, accuracy is 0.990234.\n",
      "2019-04-17 21:49:02.919137 after 35092 training step(s), loss on training batch is 0.0844, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 21:49:22.203890 after 35189 training step(s), loss on training batch is 0.0755, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 21:49:41.504374 after 35286 training step(s), loss on training batch is 0.0822, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 21:50:00.393004 after 35382 training step(s), loss on training batch is 0.0751, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 21:50:19.593055 after 35479 training step(s), loss on training batch is 0.0756, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 21:50:38.731983 after 35576 training step(s), loss on training batch is 0.0734, learning rate is 0.000000, accuracy is 0.998047.\n",
      "2019-04-17 21:50:57.343182 after 35672 training step(s), loss on training batch is 0.0822, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 21:51:16.436095 after 35769 training step(s), loss on training batch is 0.0754, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 21:51:35.693851 after 35866 training step(s), loss on training batch is 0.0792, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 21:51:54.347057 after 35962 training step(s), loss on training batch is 0.0817, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 21:52:13.368810 after 36059 training step(s), loss on training batch is 0.0759, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 21:52:32.442962 after 36156 training step(s), loss on training batch is 0.0783, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 21:52:51.500577 after 36252 training step(s), loss on training batch is 0.0750, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 21:53:10.500112 after 36349 training step(s), loss on training batch is 0.0729, learning rate is 0.000000, accuracy is 0.998047.\n",
      "2019-04-17 21:53:29.547150 after 36446 training step(s), loss on training batch is 0.0837, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 21:53:48.229740 after 36542 training step(s), loss on training batch is 0.0754, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 21:54:07.359453 after 36639 training step(s), loss on training batch is 0.0786, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 21:54:26.503449 after 36736 training step(s), loss on training batch is 0.0773, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 21:54:45.328899 after 36832 training step(s), loss on training batch is 0.0778, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 21:55:04.326250 after 36929 training step(s), loss on training batch is 0.0754, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 21:55:23.304775 after 37026 training step(s), loss on training batch is 0.0821, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 21:55:41.974832 after 37122 training step(s), loss on training batch is 0.0775, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 21:56:00.806457 after 37219 training step(s), loss on training batch is 0.0766, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 21:56:20.125609 after 37316 training step(s), loss on training batch is 0.0808, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 21:56:38.785556 after 37412 training step(s), loss on training batch is 0.0786, learning rate is 0.000000, accuracy is 0.992188.\n",
      "2019-04-17 21:56:57.911532 after 37509 training step(s), loss on training batch is 0.0805, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 21:57:17.078668 after 37606 training step(s), loss on training batch is 0.0790, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 21:57:35.577191 after 37702 training step(s), loss on training batch is 0.0756, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 21:57:54.642030 after 37799 training step(s), loss on training batch is 0.0783, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 21:58:13.809987 after 37896 training step(s), loss on training batch is 0.0784, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 21:58:32.574750 after 37992 training step(s), loss on training batch is 0.0794, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 21:58:51.740431 after 38089 training step(s), loss on training batch is 0.0787, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 21:59:10.736746 after 38186 training step(s), loss on training batch is 0.0787, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 21:59:29.390696 after 38282 training step(s), loss on training batch is 0.0805, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 21:59:48.517592 after 38379 training step(s), loss on training batch is 0.0795, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:00:07.514555 after 38476 training step(s), loss on training batch is 0.0826, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 22:00:26.348077 after 38572 training step(s), loss on training batch is 0.0789, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 22:00:45.402367 after 38669 training step(s), loss on training batch is 0.0767, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:01:04.586722 after 38766 training step(s), loss on training batch is 0.0805, learning rate is 0.000000, accuracy is 0.992188.\n",
      "2019-04-17 22:01:23.235020 after 38862 training step(s), loss on training batch is 0.0742, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 22:01:42.262536 after 38959 training step(s), loss on training batch is 0.0747, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 22:02:01.138325 after 39056 training step(s), loss on training batch is 0.0816, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:02:19.619629 after 39152 training step(s), loss on training batch is 0.0791, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:02:38.906346 after 39249 training step(s), loss on training batch is 0.0773, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:02:58.255608 after 39346 training step(s), loss on training batch is 0.0843, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:03:16.936468 after 39442 training step(s), loss on training batch is 0.0803, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:03:36.136046 after 39539 training step(s), loss on training batch is 0.0831, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:03:55.266925 after 39636 training step(s), loss on training batch is 0.0781, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:04:14.047114 after 39732 training step(s), loss on training batch is 0.0768, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:04:33.130396 after 39829 training step(s), loss on training batch is 0.0723, learning rate is 0.000000, accuracy is 0.999023.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-17 22:04:52.196943 after 39926 training step(s), loss on training batch is 0.0838, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 22:05:10.839364 after 40022 training step(s), loss on training batch is 0.0772, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:05:30.008060 after 40119 training step(s), loss on training batch is 0.0735, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:05:49.053097 after 40216 training step(s), loss on training batch is 0.0795, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:06:07.358949 after 40312 training step(s), loss on training batch is 0.0809, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 22:06:26.546836 after 40409 training step(s), loss on training batch is 0.0826, learning rate is 0.000000, accuracy is 0.992188.\n",
      "2019-04-17 22:06:45.577777 after 40506 training step(s), loss on training batch is 0.0792, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:07:04.673674 after 40602 training step(s), loss on training batch is 0.0914, learning rate is 0.000000, accuracy is 0.988281.\n",
      "2019-04-17 22:07:23.694673 after 40699 training step(s), loss on training batch is 0.0742, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 22:07:42.802078 after 40796 training step(s), loss on training batch is 0.0767, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 22:08:01.656437 after 40892 training step(s), loss on training batch is 0.0788, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:08:20.811350 after 40989 training step(s), loss on training batch is 0.0734, learning rate is 0.000000, accuracy is 0.998047.\n",
      "2019-04-17 22:08:39.764708 after 41086 training step(s), loss on training batch is 0.0766, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 22:08:58.561725 after 41182 training step(s), loss on training batch is 0.0758, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:09:17.554246 after 41279 training step(s), loss on training batch is 0.0738, learning rate is 0.000000, accuracy is 0.998047.\n",
      "2019-04-17 22:09:36.579334 after 41376 training step(s), loss on training batch is 0.0834, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:09:55.372846 after 41472 training step(s), loss on training batch is 0.0797, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:10:14.480323 after 41569 training step(s), loss on training batch is 0.0767, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 22:10:33.459243 after 41666 training step(s), loss on training batch is 0.0807, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:10:52.179154 after 41762 training step(s), loss on training batch is 0.0817, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 22:11:11.458252 after 41859 training step(s), loss on training batch is 0.0772, learning rate is 0.000000, accuracy is 0.998047.\n",
      "2019-04-17 22:11:30.450830 after 41956 training step(s), loss on training batch is 0.0830, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 22:11:49.304026 after 42052 training step(s), loss on training batch is 0.0786, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:12:08.626165 after 42149 training step(s), loss on training batch is 0.0759, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:12:27.638248 after 42246 training step(s), loss on training batch is 0.0866, learning rate is 0.000000, accuracy is 0.992188.\n",
      "2019-04-17 22:12:46.772951 after 42342 training step(s), loss on training batch is 0.0772, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:13:05.945783 after 42439 training step(s), loss on training batch is 0.0772, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:13:24.885108 after 42536 training step(s), loss on training batch is 0.0777, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:13:43.563005 after 42632 training step(s), loss on training batch is 0.0790, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 22:14:02.672408 after 42729 training step(s), loss on training batch is 0.0765, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:14:21.870500 after 42826 training step(s), loss on training batch is 0.0796, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:14:40.635453 after 42922 training step(s), loss on training batch is 0.0769, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:14:59.956988 after 43019 training step(s), loss on training batch is 0.0756, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:15:18.813672 after 43116 training step(s), loss on training batch is 0.0886, learning rate is 0.000000, accuracy is 0.991211.\n",
      "2019-04-17 22:15:37.473343 after 43212 training step(s), loss on training batch is 0.0808, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:15:56.718703 after 43309 training step(s), loss on training batch is 0.0719, learning rate is 0.000000, accuracy is 0.998047.\n",
      "2019-04-17 22:16:16.149475 after 43406 training step(s), loss on training batch is 0.0784, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:16:34.985476 after 43502 training step(s), loss on training batch is 0.0784, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:16:54.505446 after 43599 training step(s), loss on training batch is 0.0786, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 22:17:13.717329 after 43696 training step(s), loss on training batch is 0.0788, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:17:32.368236 after 43792 training step(s), loss on training batch is 0.0815, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:17:51.420691 after 43889 training step(s), loss on training batch is 0.0732, learning rate is 0.000000, accuracy is 0.999023.\n",
      "2019-04-17 22:18:10.851182 after 43986 training step(s), loss on training batch is 0.0786, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:18:29.593973 after 44082 training step(s), loss on training batch is 0.0761, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:18:48.945170 after 44179 training step(s), loss on training batch is 0.0781, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 22:19:08.198498 after 44276 training step(s), loss on training batch is 0.0832, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 22:19:26.907094 after 44372 training step(s), loss on training batch is 0.0793, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:19:46.056622 after 44469 training step(s), loss on training batch is 0.0817, learning rate is 0.000000, accuracy is 0.991211.\n",
      "2019-04-17 22:20:05.157554 after 44566 training step(s), loss on training batch is 0.0770, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:20:23.793647 after 44662 training step(s), loss on training batch is 0.0801, learning rate is 0.000000, accuracy is 0.992188.\n",
      "2019-04-17 22:20:43.459541 after 44759 training step(s), loss on training batch is 0.0801, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:21:02.436010 after 44856 training step(s), loss on training batch is 0.0894, learning rate is 0.000000, accuracy is 0.987305.\n",
      "2019-04-17 22:21:21.111358 after 44952 training step(s), loss on training batch is 0.0807, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 22:21:40.206418 after 45049 training step(s), loss on training batch is 0.0733, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:21:59.220263 after 45146 training step(s), loss on training batch is 0.0853, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:22:17.855355 after 45242 training step(s), loss on training batch is 0.0739, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 22:22:36.920299 after 45339 training step(s), loss on training batch is 0.0803, learning rate is 0.000000, accuracy is 0.991211.\n",
      "2019-04-17 22:22:56.125029 after 45436 training step(s), loss on training batch is 0.0757, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:23:14.840764 after 45532 training step(s), loss on training batch is 0.0785, learning rate is 0.000000, accuracy is 0.994141.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-17 22:23:34.035470 after 45629 training step(s), loss on training batch is 0.0759, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 22:23:53.091526 after 45726 training step(s), loss on training batch is 0.0790, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:24:11.924845 after 45822 training step(s), loss on training batch is 0.0750, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 22:24:31.254774 after 45919 training step(s), loss on training batch is 0.0757, learning rate is 0.000000, accuracy is 0.998047.\n",
      "2019-04-17 22:24:50.376633 after 46016 training step(s), loss on training batch is 0.0816, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:25:09.402285 after 46112 training step(s), loss on training batch is 0.0739, learning rate is 0.000000, accuracy is 0.998047.\n",
      "2019-04-17 22:25:28.533941 after 46209 training step(s), loss on training batch is 0.0804, learning rate is 0.000000, accuracy is 0.992188.\n",
      "2019-04-17 22:25:47.570614 after 46306 training step(s), loss on training batch is 0.0778, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:26:06.188620 after 46402 training step(s), loss on training batch is 0.0856, learning rate is 0.000000, accuracy is 0.990234.\n",
      "2019-04-17 22:26:25.257811 after 46499 training step(s), loss on training batch is 0.0774, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:26:44.235931 after 46596 training step(s), loss on training batch is 0.0819, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:27:03.436091 after 46692 training step(s), loss on training batch is 0.0800, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 22:27:22.596528 after 46789 training step(s), loss on training batch is 0.0753, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 22:27:41.723587 after 46886 training step(s), loss on training batch is 0.0797, learning rate is 0.000000, accuracy is 0.992188.\n",
      "2019-04-17 22:28:00.273275 after 46982 training step(s), loss on training batch is 0.0807, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:28:19.154951 after 47079 training step(s), loss on training batch is 0.0857, learning rate is 0.000000, accuracy is 0.992188.\n",
      "2019-04-17 22:28:38.371583 after 47176 training step(s), loss on training batch is 0.0801, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:28:56.935172 after 47272 training step(s), loss on training batch is 0.0745, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 22:29:16.109638 after 47369 training step(s), loss on training batch is 0.0771, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:29:35.316589 after 47466 training step(s), loss on training batch is 0.0802, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:29:54.194779 after 47562 training step(s), loss on training batch is 0.0818, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:30:13.185938 after 47659 training step(s), loss on training batch is 0.0744, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:30:32.436028 after 47756 training step(s), loss on training batch is 0.0803, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:30:51.094327 after 47852 training step(s), loss on training batch is 0.0813, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:31:09.990749 after 47949 training step(s), loss on training batch is 0.0784, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:31:29.215125 after 48046 training step(s), loss on training batch is 0.0852, learning rate is 0.000000, accuracy is 0.991211.\n",
      "2019-04-17 22:31:47.844815 after 48142 training step(s), loss on training batch is 0.0759, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 22:32:06.940357 after 48239 training step(s), loss on training batch is 0.0732, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 22:32:26.158031 after 48336 training step(s), loss on training batch is 0.0810, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:32:44.772536 after 48432 training step(s), loss on training batch is 0.0769, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:33:03.815559 after 48529 training step(s), loss on training batch is 0.0743, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:33:22.876885 after 48626 training step(s), loss on training batch is 0.0784, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:33:41.768230 after 48722 training step(s), loss on training batch is 0.0786, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 22:34:00.746412 after 48819 training step(s), loss on training batch is 0.0735, learning rate is 0.000000, accuracy is 0.998047.\n",
      "2019-04-17 22:34:19.816888 after 48916 training step(s), loss on training batch is 0.0752, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:34:38.678722 after 49012 training step(s), loss on training batch is 0.0775, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:34:57.662863 after 49109 training step(s), loss on training batch is 0.0749, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:35:16.733522 after 49206 training step(s), loss on training batch is 0.0842, learning rate is 0.000000, accuracy is 0.992188.\n",
      "2019-04-17 22:35:35.445197 after 49302 training step(s), loss on training batch is 0.0787, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:35:54.503355 after 49399 training step(s), loss on training batch is 0.0758, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:36:13.707780 after 49496 training step(s), loss on training batch is 0.0784, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 22:36:32.354350 after 49592 training step(s), loss on training batch is 0.0747, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:36:50.638918 after 49689 training step(s), loss on training batch is 0.0754, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:37:08.201277 after 49786 training step(s), loss on training batch is 0.0871, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 22:37:25.356334 after 49882 training step(s), loss on training batch is 0.0778, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:37:43.216677 after 49979 training step(s), loss on training batch is 0.0828, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:38:01.426216 after 50076 training step(s), loss on training batch is 0.0786, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:38:20.311887 after 50172 training step(s), loss on training batch is 0.0734, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 22:38:39.739281 after 50269 training step(s), loss on training batch is 0.0797, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:38:58.992212 after 50366 training step(s), loss on training batch is 0.0851, learning rate is 0.000000, accuracy is 0.991211.\n",
      "2019-04-17 22:39:17.463693 after 50462 training step(s), loss on training batch is 0.0743, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:39:34.813342 after 50559 training step(s), loss on training batch is 0.0788, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:39:52.255479 after 50656 training step(s), loss on training batch is 0.0831, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 22:40:09.427227 after 50752 training step(s), loss on training batch is 0.0753, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 22:40:26.916088 after 50849 training step(s), loss on training batch is 0.0729, learning rate is 0.000000, accuracy is 0.998047.\n",
      "2019-04-17 22:40:44.239707 after 50946 training step(s), loss on training batch is 0.0749, learning rate is 0.000000, accuracy is 0.999023.\n",
      "2019-04-17 22:41:01.331362 after 51042 training step(s), loss on training batch is 0.0808, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:41:18.606779 after 51139 training step(s), loss on training batch is 0.0747, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:41:36.020927 after 51236 training step(s), loss on training batch is 0.0814, learning rate is 0.000000, accuracy is 0.997070.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-17 22:41:53.113887 after 51332 training step(s), loss on training batch is 0.0746, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:42:10.653595 after 51429 training step(s), loss on training batch is 0.0782, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:42:28.247803 after 51526 training step(s), loss on training batch is 0.0815, learning rate is 0.000000, accuracy is 0.992188.\n",
      "2019-04-17 22:42:45.395549 after 51622 training step(s), loss on training batch is 0.0799, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 22:43:02.757269 after 51719 training step(s), loss on training batch is 0.0798, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:43:20.292567 after 51816 training step(s), loss on training batch is 0.0941, learning rate is 0.000000, accuracy is 0.987305.\n",
      "2019-04-17 22:43:37.377707 after 51912 training step(s), loss on training batch is 0.0815, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 22:43:54.797546 after 52009 training step(s), loss on training batch is 0.0771, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:44:12.372379 after 52106 training step(s), loss on training batch is 0.0822, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 22:44:29.491981 after 52202 training step(s), loss on training batch is 0.0781, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:44:46.964612 after 52299 training step(s), loss on training batch is 0.0773, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:45:04.368497 after 52396 training step(s), loss on training batch is 0.0819, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 22:45:21.853033 after 52492 training step(s), loss on training batch is 0.0802, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:45:39.498349 after 52589 training step(s), loss on training batch is 0.0744, learning rate is 0.000000, accuracy is 0.998047.\n",
      "2019-04-17 22:45:57.080376 after 52686 training step(s), loss on training batch is 0.0806, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 22:46:14.208300 after 52782 training step(s), loss on training batch is 0.0852, learning rate is 0.000000, accuracy is 0.991211.\n",
      "2019-04-17 22:46:31.788367 after 52879 training step(s), loss on training batch is 0.0806, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 22:46:49.180789 after 52976 training step(s), loss on training batch is 0.0797, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:47:06.277453 after 53072 training step(s), loss on training batch is 0.0761, learning rate is 0.000000, accuracy is 0.998047.\n",
      "2019-04-17 22:47:23.899159 after 53169 training step(s), loss on training batch is 0.0771, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:47:41.432927 after 53266 training step(s), loss on training batch is 0.0821, learning rate is 0.000000, accuracy is 0.992188.\n",
      "2019-04-17 22:47:58.607100 after 53362 training step(s), loss on training batch is 0.0735, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 22:48:16.299063 after 53459 training step(s), loss on training batch is 0.0756, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:48:33.889547 after 53556 training step(s), loss on training batch is 0.0836, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:48:51.047237 after 53652 training step(s), loss on training batch is 0.0855, learning rate is 0.000000, accuracy is 0.991211.\n",
      "2019-04-17 22:49:08.509357 after 53749 training step(s), loss on training batch is 0.0877, learning rate is 0.000000, accuracy is 0.992188.\n",
      "2019-04-17 22:49:25.898007 after 53846 training step(s), loss on training batch is 0.0800, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:49:42.981936 after 53942 training step(s), loss on training batch is 0.0817, learning rate is 0.000000, accuracy is 0.991211.\n",
      "2019-04-17 22:50:00.489772 after 54039 training step(s), loss on training batch is 0.0814, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 22:50:18.137706 after 54136 training step(s), loss on training batch is 0.0788, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:50:35.285860 after 54232 training step(s), loss on training batch is 0.0803, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:50:52.708450 after 54329 training step(s), loss on training batch is 0.0791, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:51:10.088353 after 54426 training step(s), loss on training batch is 0.0813, learning rate is 0.000000, accuracy is 0.992188.\n",
      "2019-04-17 22:51:27.107520 after 54522 training step(s), loss on training batch is 0.0801, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:51:44.631116 after 54619 training step(s), loss on training batch is 0.0813, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:52:02.115245 after 54716 training step(s), loss on training batch is 0.0795, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:52:19.197886 after 54812 training step(s), loss on training batch is 0.0793, learning rate is 0.000000, accuracy is 0.991211.\n",
      "2019-04-17 22:52:36.831851 after 54909 training step(s), loss on training batch is 0.0798, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 22:52:54.435325 after 55006 training step(s), loss on training batch is 0.0826, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:53:11.481109 after 55102 training step(s), loss on training batch is 0.0800, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:53:28.695637 after 55199 training step(s), loss on training batch is 0.0750, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:53:46.257912 after 55296 training step(s), loss on training batch is 0.0833, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:54:03.194215 after 55392 training step(s), loss on training batch is 0.0812, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:54:20.822327 after 55489 training step(s), loss on training batch is 0.0843, learning rate is 0.000000, accuracy is 0.991211.\n",
      "2019-04-17 22:54:38.215819 after 55586 training step(s), loss on training batch is 0.0849, learning rate is 0.000000, accuracy is 0.991211.\n",
      "2019-04-17 22:54:55.437653 after 55682 training step(s), loss on training batch is 0.0734, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 22:55:13.106851 after 55779 training step(s), loss on training batch is 0.0772, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:55:30.575332 after 55876 training step(s), loss on training batch is 0.0834, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:55:47.822698 after 55972 training step(s), loss on training batch is 0.0793, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:56:05.407517 after 56069 training step(s), loss on training batch is 0.0779, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 22:56:22.903510 after 56166 training step(s), loss on training batch is 0.0838, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 22:56:40.037053 after 56262 training step(s), loss on training batch is 0.0775, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:56:57.497493 after 56359 training step(s), loss on training batch is 0.0749, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:57:15.044356 after 56456 training step(s), loss on training batch is 0.0783, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:57:32.023035 after 56552 training step(s), loss on training batch is 0.0767, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 22:57:49.429537 after 56649 training step(s), loss on training batch is 0.0747, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 22:58:07.026591 after 56746 training step(s), loss on training batch is 0.0825, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 22:58:23.969713 after 56842 training step(s), loss on training batch is 0.0772, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 22:58:41.478271 after 56939 training step(s), loss on training batch is 0.0744, learning rate is 0.000000, accuracy is 0.997070.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-17 22:58:58.951250 after 57036 training step(s), loss on training batch is 0.0757, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 22:59:16.301069 after 57132 training step(s), loss on training batch is 0.0764, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:59:33.664982 after 57229 training step(s), loss on training batch is 0.0799, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 22:59:51.164691 after 57326 training step(s), loss on training batch is 0.0779, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 23:00:08.253931 after 57422 training step(s), loss on training batch is 0.0753, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 23:00:25.613637 after 57519 training step(s), loss on training batch is 0.0721, learning rate is 0.000000, accuracy is 0.998047.\n",
      "2019-04-17 23:00:43.108793 after 57616 training step(s), loss on training batch is 0.0811, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 23:01:00.217738 after 57712 training step(s), loss on training batch is 0.0785, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 23:01:17.862109 after 57809 training step(s), loss on training batch is 0.0756, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 23:01:35.525482 after 57906 training step(s), loss on training batch is 0.0820, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 23:01:52.683899 after 58002 training step(s), loss on training batch is 0.0758, learning rate is 0.000000, accuracy is 0.998047.\n",
      "2019-04-17 23:02:10.119872 after 58099 training step(s), loss on training batch is 0.0738, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 23:02:27.709572 after 58196 training step(s), loss on training batch is 0.0920, learning rate is 0.000000, accuracy is 0.991211.\n",
      "2019-04-17 23:02:44.799453 after 58292 training step(s), loss on training batch is 0.0766, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 23:03:02.233783 after 58389 training step(s), loss on training batch is 0.0733, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 23:03:19.572011 after 58486 training step(s), loss on training batch is 0.0747, learning rate is 0.000000, accuracy is 0.998047.\n",
      "2019-04-17 23:03:36.871549 after 58582 training step(s), loss on training batch is 0.0812, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 23:03:54.507781 after 58679 training step(s), loss on training batch is 0.0767, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 23:04:11.927134 after 58776 training step(s), loss on training batch is 0.0792, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 23:04:29.147497 after 58872 training step(s), loss on training batch is 0.0791, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 23:04:46.659096 after 58969 training step(s), loss on training batch is 0.0761, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 23:05:04.198562 after 59066 training step(s), loss on training batch is 0.0802, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 23:05:21.302251 after 59162 training step(s), loss on training batch is 0.0759, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 23:05:38.758336 after 59259 training step(s), loss on training batch is 0.0825, learning rate is 0.000000, accuracy is 0.992188.\n",
      "2019-04-17 23:05:56.126426 after 59356 training step(s), loss on training batch is 0.0848, learning rate is 0.000000, accuracy is 0.992188.\n",
      "2019-04-17 23:06:13.224487 after 59452 training step(s), loss on training batch is 0.0764, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 23:06:30.710303 after 59549 training step(s), loss on training batch is 0.0767, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 23:06:48.144599 after 59646 training step(s), loss on training batch is 0.0827, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 23:07:05.372578 after 59742 training step(s), loss on training batch is 0.0874, learning rate is 0.000000, accuracy is 0.991211.\n",
      "2019-04-17 23:07:23.031948 after 59839 training step(s), loss on training batch is 0.0793, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 23:07:40.297859 after 59936 training step(s), loss on training batch is 0.0835, learning rate is 0.000000, accuracy is 0.992188.\n",
      "2019-04-17 23:07:57.335322 after 60032 training step(s), loss on training batch is 0.0844, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 23:08:14.819695 after 60129 training step(s), loss on training batch is 0.0820, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 23:08:32.651143 after 60226 training step(s), loss on training batch is 0.0777, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 23:08:49.888314 after 60322 training step(s), loss on training batch is 0.0766, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 23:09:07.275044 after 60419 training step(s), loss on training batch is 0.0802, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 23:09:24.605405 after 60516 training step(s), loss on training batch is 0.0765, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 23:09:42.008056 after 60612 training step(s), loss on training batch is 0.0769, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 23:09:59.621621 after 60709 training step(s), loss on training batch is 0.0752, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 23:10:17.163712 after 60806 training step(s), loss on training batch is 0.0778, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 23:10:34.044074 after 60902 training step(s), loss on training batch is 0.0770, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 23:10:51.738134 after 60999 training step(s), loss on training batch is 0.0862, learning rate is 0.000000, accuracy is 0.992188.\n",
      "2019-04-17 23:11:09.312296 after 61096 training step(s), loss on training batch is 0.0797, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 23:11:26.508681 after 61192 training step(s), loss on training batch is 0.0781, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 23:11:44.127219 after 61289 training step(s), loss on training batch is 0.0795, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 23:12:01.597342 after 61386 training step(s), loss on training batch is 0.0858, learning rate is 0.000000, accuracy is 0.992188.\n",
      "2019-04-17 23:12:18.855092 after 61482 training step(s), loss on training batch is 0.0783, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 23:12:36.511305 after 61579 training step(s), loss on training batch is 0.0744, learning rate is 0.000000, accuracy is 0.998047.\n",
      "2019-04-17 23:12:53.967639 after 61676 training step(s), loss on training batch is 0.0792, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 23:13:11.253883 after 61772 training step(s), loss on training batch is 0.0760, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 23:13:28.955050 after 61869 training step(s), loss on training batch is 0.0795, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 23:13:46.483693 after 61966 training step(s), loss on training batch is 0.0819, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 23:14:03.643688 after 62062 training step(s), loss on training batch is 0.0826, learning rate is 0.000000, accuracy is 0.992188.\n",
      "2019-04-17 23:14:21.332691 after 62159 training step(s), loss on training batch is 0.0755, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 23:14:38.843761 after 62256 training step(s), loss on training batch is 0.0797, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 23:14:55.979617 after 62352 training step(s), loss on training batch is 0.0832, learning rate is 0.000000, accuracy is 0.992188.\n",
      "2019-04-17 23:15:13.341930 after 62449 training step(s), loss on training batch is 0.0742, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 23:15:31.133069 after 62546 training step(s), loss on training batch is 0.0815, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 23:15:48.111598 after 62642 training step(s), loss on training batch is 0.0787, learning rate is 0.000000, accuracy is 0.994141.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-17 23:16:05.687044 after 62739 training step(s), loss on training batch is 0.0743, learning rate is 0.000000, accuracy is 0.998047.\n",
      "2019-04-17 23:16:23.291907 after 62836 training step(s), loss on training batch is 0.0847, learning rate is 0.000000, accuracy is 0.992188.\n",
      "2019-04-17 23:16:40.340577 after 62932 training step(s), loss on training batch is 0.0788, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 23:16:57.821690 after 63029 training step(s), loss on training batch is 0.0787, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 23:17:15.291862 after 63126 training step(s), loss on training batch is 0.0812, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 23:17:32.583215 after 63222 training step(s), loss on training batch is 0.0775, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 23:17:50.410931 after 63319 training step(s), loss on training batch is 0.0756, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 23:18:07.956184 after 63416 training step(s), loss on training batch is 0.0827, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 23:18:25.299539 after 63512 training step(s), loss on training batch is 0.0784, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 23:18:42.783445 after 63609 training step(s), loss on training batch is 0.0771, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 23:19:00.217368 after 63706 training step(s), loss on training batch is 0.0809, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 23:19:17.370232 after 63802 training step(s), loss on training batch is 0.0763, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 23:19:34.781391 after 63899 training step(s), loss on training batch is 0.0769, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 23:19:52.378495 after 63996 training step(s), loss on training batch is 0.0851, learning rate is 0.000000, accuracy is 0.991211.\n",
      "2019-04-17 23:20:09.425857 after 64092 training step(s), loss on training batch is 0.0778, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 23:20:27.093189 after 64189 training step(s), loss on training batch is 0.0783, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 23:20:44.844160 after 64286 training step(s), loss on training batch is 0.0767, learning rate is 0.000000, accuracy is 0.997070.\n",
      "2019-04-17 23:21:01.867987 after 64382 training step(s), loss on training batch is 0.0760, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 23:21:19.485513 after 64479 training step(s), loss on training batch is 0.0768, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 23:21:36.944059 after 64576 training step(s), loss on training batch is 0.0820, learning rate is 0.000000, accuracy is 0.992188.\n",
      "2019-04-17 23:21:54.251398 after 64672 training step(s), loss on training batch is 0.0800, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 23:22:11.679527 after 64769 training step(s), loss on training batch is 0.0796, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 23:22:29.315245 after 64866 training step(s), loss on training batch is 0.0784, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 23:22:46.402087 after 64962 training step(s), loss on training batch is 0.0801, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 23:23:03.735450 after 65059 training step(s), loss on training batch is 0.0751, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 23:23:21.146872 after 65156 training step(s), loss on training batch is 0.0819, learning rate is 0.000000, accuracy is 0.993164.\n",
      "2019-04-17 23:23:38.263091 after 65252 training step(s), loss on training batch is 0.0735, learning rate is 0.000000, accuracy is 0.998047.\n",
      "2019-04-17 23:23:55.652287 after 65349 training step(s), loss on training batch is 0.0767, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 23:24:13.040338 after 65446 training step(s), loss on training batch is 0.0799, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 23:24:30.311320 after 65542 training step(s), loss on training batch is 0.0795, learning rate is 0.000000, accuracy is 0.995117.\n",
      "2019-04-17 23:24:47.899737 after 65639 training step(s), loss on training batch is 0.0752, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 23:25:05.460375 after 65736 training step(s), loss on training batch is 0.0816, learning rate is 0.000000, accuracy is 0.994141.\n",
      "2019-04-17 23:25:22.649676 after 65832 training step(s), loss on training batch is 0.0722, learning rate is 0.000000, accuracy is 0.998047.\n",
      "2019-04-17 23:25:40.037516 after 65929 training step(s), loss on training batch is 0.0772, learning rate is 0.000000, accuracy is 0.996094.\n",
      "2019-04-17 23:25:57.472575 after 66026 training step(s), loss on training batch is 0.0766, learning rate is 0.000000, accuracy is 0.997070.\n"
     ]
    }
   ],
   "source": [
    "# !/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "import re\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,2,3,4\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "\n",
    "\n",
    "INPUT_NODE = 2304\n",
    "OUTPUT_NODE = 7\n",
    "LAYER1_NODE = 4096\n",
    "LAYER2_NODE = 512\n",
    "LAYER3_NODE = 64\n",
    "BATCH_SIZE = 1024\n",
    "LEARNING_RATE_BASE = 0.01\n",
    "LEARNING_RATE_DECAY = 0.992\n",
    "REGULARIZER = 0.0001\n",
    "STEPS = 100000\n",
    "MOVING_AVERAGE_DECAY = 0.99\n",
    "TEST_INTERVAL_SECS = 1\n",
    "MODEL_SAVE_PATH=\"check_point_next\"\n",
    "MODEL_NAME=\"data_model\"\n",
    "\n",
    "\n",
    "\n",
    "def get_weight(shape, regularizer):\n",
    "    w = tf.Variable(tf.truncated_normal(shape, stddev=0.1,mean=0))\n",
    "    #损失函数loss含正则化regularization\n",
    "    if regularizer != None: tf.add_to_collection('losses', tf.contrib.layers.l2_regularizer(regularizer)(w))\n",
    "    return w\n",
    "\n",
    "\n",
    "def get_bias(shape):\n",
    "    b = tf.Variable(tf.zeros(shape))\n",
    "    return b\n",
    "\n",
    "\n",
    "def conv2d(x, W):\n",
    "    # stride[1, x_movement, y_movement, 1]\n",
    "    # Must have strides[0] = strides[3] =1，意思是不对样本个数和channel进行卷积\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding=\"SAME\")  # padding=\"SAME\"用零填充边界\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "\n",
    "\n",
    "def forward(x, regularizer):\n",
    " \n",
    "    x = tf.reshape(x, [-1, 48, 48, 1])\n",
    "    \n",
    "    ## convl layer ##\n",
    "    W_conv1 = get_weight([5,5,1,128],None) # kernel 5*5, channel is 1, out size 32\n",
    "    b_conv1 = get_bias([128])\n",
    "    h_conv1 = tf.nn.relu(conv2d(x,W_conv1) + b_conv1)  # output size 28*28*32\n",
    "    h_pool1 = max_pool_2x2(h_conv1)                          # output size 14*14*32\n",
    "    \n",
    "    ## conv2 layer ##\n",
    "    W_conv2 = get_weight([5,5,128,64],None) # kernel 5*5, in size 32, out size 64\n",
    "    b_conv2 = get_bias([64])\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2) + b_conv2)  # output size 14*14*64\n",
    "    h_pool2 = max_pool_2x2(h_conv2)                          # output size 7*7*64\n",
    "    \n",
    "    ## conv3 layer ##\n",
    "    W_conv3 = get_weight([5,5,64,32],None) # kernel 5*5, in size 32, out size 64\n",
    "    b_conv3 = get_bias([32])\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_pool2,W_conv3) + b_conv3)  # output size 14*14*64\n",
    "    h_pool3 = max_pool_2x2(h_conv3)                          # output size 7*7*64\n",
    "    \n",
    "    ## funcl layer ##\n",
    "    W_fc1 = get_weight([1*6*6*32, 576], regularizer)\n",
    "    b_fc1 = get_bias([576])\n",
    "    \n",
    "    h_pool2_flat = tf.reshape(h_pool3, [-1, 1*6*6*32])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob = 0.5)\n",
    "    \n",
    "    ## func2 layer ##\n",
    "    W_fc2 = get_weight([576, 128], regularizer)\n",
    "    b_fc2 = get_bias([128])\n",
    "    y1 = tf.nn.relu(tf.matmul(h_fc1_drop,W_fc2)+b_fc2)\n",
    "    \n",
    "    W_fc3 = get_weight([128, OUTPUT_NODE], regularizer)\n",
    "    b_fc3 = get_bias([OUTPUT_NODE])\n",
    "    y = (tf.matmul(y1,W_fc3)+b_fc3)\n",
    "    tf.add_to_collection('pred_network', y)  # 用于加载模型获取要预测的网络结构\n",
    "    return W_fc1,b_fc1,h_fc1,W_fc2,b_fc2,y\n",
    "\n",
    "\n",
    "def backward(new_data):\n",
    "    step_train = 0\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "    \n",
    "    np.random.shuffle(new_data)\n",
    "\n",
    "\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, [None, INPUT_NODE],name='x')\n",
    "    y_ = tf.placeholder(tf.float32, [None, OUTPUT_NODE])\n",
    "\n",
    "    w1, b1, y1, w2, b2,y = forward(x, REGULARIZER)\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "    #损失函数loss含正则化regularization\n",
    "    ce = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1))\n",
    "    cem = tf.reduce_mean(ce)\n",
    "    loss = cem + tf.add_n(tf.get_collection('losses'))\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "    accuracy = tf.reduce_mean(correct_prediction)\n",
    "    \n",
    "    #指数衰减学习率\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "        LEARNING_RATE_BASE,\n",
    "        global_step,\n",
    "        len(new_data) / BATCH_SIZE,\n",
    "        LEARNING_RATE_DECAY,\n",
    "        staircase=True)\n",
    "\n",
    "\n",
    "\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "    #滑动平均\n",
    "    ema = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n",
    "    ema_op = ema.apply(tf.trainable_variables())\n",
    "\n",
    "    with tf.control_dependencies([train_step, ema_op]):\n",
    "        train_op = tf.no_op(name='train')\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session(config = config) as sess:\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        sess.run(init_op)\n",
    "\n",
    "        ckpt = tf.train.get_checkpoint_state(MODEL_SAVE_PATH)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "        for i in range(STEPS):\n",
    "            #每次读入BATCH_SIZE组数据和标签\n",
    "\n",
    "            if(step_train > len(new_data)):\n",
    "                step_train = 0\n",
    "\n",
    "                continue\n",
    "            else:\n",
    "                xs = new_data[step_train:step_train+BATCH_SIZE,:2304]\n",
    "\n",
    "                ys = new_data[step_train:step_train+BATCH_SIZE,2304:]\n",
    "            step_train = step_train + BATCH_SIZE\n",
    "\n",
    "\n",
    "            _, loss_value, step, accuracy_train = sess.run([train_op, loss, global_step, accuracy], feed_dict={x: xs, y_: ys, keep_prob:1})\n",
    "\n",
    "            if i % 100 == 0:\n",
    "\n",
    "                print(\"%s after %d training step(s), loss on training batch is %.4f, learning rate is %f, accuracy is %f.\" % (datetime.now(),step, loss_value,learning_rate.eval(),accuracy_train))\n",
    "                #print(\"w1 = \", (sess.run(w1)))\n",
    "\n",
    "                saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME), global_step=global_step)\n",
    "    print(\"finish！\")\n",
    "\n",
    "\n",
    "def test(new_data):\n",
    "    \n",
    "\n",
    "    np.random.shuffle(new_data)\n",
    "    new_data = new_data[0:1500]\n",
    "    with tf.Graph().as_default() as g:\n",
    "        x = tf.placeholder(tf.float32, [None, INPUT_NODE])\n",
    "        y_ = tf.placeholder(tf.float32, [None, OUTPUT_NODE])\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        w1, b1, y1, w2, b2, y = forward(x, None)\n",
    "\n",
    "        xs = new_data[:, :2304]\n",
    "\n",
    "        ys = new_data[:, 2304:]\n",
    "\n",
    "        ema = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY)\n",
    "        ema_restore = ema.variables_to_restore()\n",
    "        saver = tf.train.Saver(ema_restore)\n",
    "\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "        while True:\n",
    "            with tf.Session(config=config) as sess:\n",
    "                ckpt = tf.train.get_checkpoint_state(MODEL_SAVE_PATH)\n",
    "                if ckpt and ckpt.model_checkpoint_path:\n",
    "                    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "                    global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
    "                    accuracy_score = sess.run(accuracy, feed_dict={x: xs, y_: ys, keep_prob : 0.5})\n",
    "                    print(\"After %s training step(s), test accuracy = %g\" % (global_step, accuracy_score))\n",
    "                else:\n",
    "                    print('No checkpoint file found')\n",
    "                    return\n",
    "            time.sleep(TEST_INTERVAL_SECS)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    train=True\n",
    "    \n",
    "    if train == True: \n",
    "        print(\"train!\")\n",
    "        data = pd.read_csv(\"fer2013.csv\",low_memory=False).values\n",
    "        data = data.astype(np.float32)  # change to numpy array and float32\n",
    "        data = data / 255.0\n",
    "        \n",
    "        print(\"finish fer2013!\")\n",
    "        \n",
    "        print(\"数组元素总数：\",data.size)      #打印数组尺寸，即数组元素总数  \n",
    "        print(\"数组形状：\",data.shape)         #打印数组形状 \n",
    "        print(\"数组的维度数目\",data.ndim)      #打印数组的维度数目\n",
    "        \n",
    "        backward(data)\n",
    "        \n",
    "    else:\n",
    "        print(\"test!\")\n",
    "        data = pd.read_csv(\"test.csv\",low_memory=False).values\n",
    "        data = data.astype(np.float32)  # change to numpy array and float32\n",
    "        data = data / 255.0\n",
    "        print(\"finish test!\")\n",
    "\n",
    "        print(\"数组元素总数：\",data.size)      #打印数组尺寸，即数组元素总数  \n",
    "        print(\"数组形状：\",data.shape)         #打印数组形状 \n",
    "        print(\"数组的维度数目\",data.ndim)      #打印数组的维度数目\n",
    "        \n",
    "        test(data)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    main()\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
